# =============================================================================
# КОНФИГУРАЦИЯ OPENTELEMETRY COLLECTOR - ЦЕНТРАЛЬНЫЙ АГЕНТ СБОРА ТЕЛЕМЕТРИИ
# =============================================================================
#
# OpenTelemetry Collector - это универсальный агент для сбора, обработки и 
# отправки телеметрических данных (метрики, трейсы, логи).
#
# Основные концепции:
# 1. RECEIVERS (приемники) - получают данные от приложений
# 2. PROCESSORS (обработчики) - трансформируют и обогащают данные
# 3. EXPORTERS (экспортеры) - отправляют данные в системы хранения
# 4. EXTENSIONS (расширения) - дополнительные возможности (health check, pprof)
# 5. PIPELINES (пайплайны) - связывают receivers, processors и exporters
#
# В нашей схеме: UFO App -> OpenTelemetry Collector -> Prometheus -> Grafana
# Collector получает метрики от UFO приложения и отправляет их в Prometheus

# ===================================================================
# RECEIVERS - ПРИЕМНИКИ ТЕЛЕМЕТРИЧЕСКИХ ДАННЫХ
# ===================================================================
# 
# Receivers определяют, как коллектор принимает данные от приложений.
# Каждый receiver слушает на определенном протоколе и порту.

receivers:
  # OTLP (OpenTelemetry Protocol) Receiver
  # Это стандартный протокол OpenTelemetry для передачи логов, метрик и трасс
  otlp:
    protocols:
      # gRPC протокол для высокопроизводительной передачи данных
      # Более эффективен чем HTTP для больших объемов данных
      grpc:
        # ENDPOINT: слушаем на всех интерфейсах (0.0.0.0) порту 4317
        # Go приложение подключается к localhost:4317
        # Стандартный порт для OTLP gRPC согласно спецификации OpenTelemetry
        endpoint: 0.0.0.0:4317

        # ДОПОЛНИТЕЛЬНЫЕ НАСТРОЙКИ (можно добавить):
        # max_recv_msg_size: 4194304  # максимальный размер сообщения (4MB)
        # keepalive:
        #   server_parameters:
        #     time: 30s                # keepalive пинг каждые 30 сек
        #     timeout: 5s              # таймаут ответа на пинг

      # HTTP протокол для передачи данных через REST API
      # Более простой в настройке, но менее эффективен чем gRPC
      # Полезен для приложений, которые не поддерживают gRPC
      http:
        # ENDPOINT: слушаем на всех интерфейсах (0.0.0.0) порту 4318
        # Go приложение подключается к localhost:4318
        # Стандартный порт для OTLP HTTP согласно спецификации OpenTelemetry
        endpoint: 0.0.0.0:4318

        # ДОПОЛНИТЕЛЬНЫЕ НАСТРОЙКИ (можно добавить):
        # cors:
        #   allowed_origins:           # разрешенные источники для CORS
        #     - "http://localhost:3000"
        #   allowed_headers:            # разрешенные заголовки
        #     - "Content-Type"
        # max_request_body_size: 4194304  # максимальный размер тела запроса (4MB)

# ===================================================================
# PROCESSORS - ОБРАБОТЧИКИ ТЕЛЕМЕТРИЧЕСКИХ ДАННЫХ
# ===================================================================
# 
# Processors модифицируют данные между приемом и отправкой.
# Они выполняются в том порядке, как указаны в pipeline.

processors:
  
  # RESOURCE PROCESSOR - обогащение метаданными на уровне ресурса
  # Добавляет информацию о сервисе ко всем логам
  resource:
    attributes:
      # НЕ переопределяем service.name в коллекторе, чтобы поддерживать несколько сервисов
      # Каждый сервис должен задавать service.name на стороне приложения

      # DEPLOYMENT ENVIRONMENT: окружение развертывания
      # Помогает различать логи из dev/staging/production
      - key: deployment.environment  
        value: dev
        action: insert  # добавляем только если атрибут не задан приложением
        
      # ДОПОЛНИТЕЛЬНЫЕ АТРИБУТЫ (примеры):
      # - key: service.version
      #   value: "1.0.0" 
      #   action: upsert
      # - key: service.instance.id
      #   from_attribute: host.name  # копировать значение из другого атрибута
      #   action: insert
  
  # BATCH PROCESSOR - группировка данных для эффективной отправки
  # Собирает логи в батчи перед отправкой в Elasticsearch
  batch:
    # РАЗМЕР БАТЧА: отправляем, когда накопится 1000 записей
    # Большие батчи = выше throughput, но больше latency
    send_batch_size: 1000
    
    # ТАЙМАУТ: отправляем принудительно через 5 секунд
    # Гарантирует, что логи не застрянут надолго в буфере
    timeout: 5s

    # Максимальное количество отправляемых элементов за один раз
    # Защищает от слишком больших пакетов
    send_batch_max_size: 1000

  # Вероятностное семплирование - этот процессор управляет объемом собираемых данных
  # Применяется только к трейсам в соответствующем пайплайне
  probabilistic_sampler:
    # Процент трейсов, которые будут сохранены
    # 100% означает сохранение всех данных (хорошо для разработки)
    # В продакшене рекомендуется более низкий процент (1-10%) для снижения нагрузки
    sampling_percentage: 100

# ===================================================================
# EXPORTERS - ЭКСПОРТЕРЫ ДАННЫХ В СИСТЕМЫ ХРАНЕНИЯ
# ===================================================================
# 
# Exporters отправляют обработанные данные во внешние системы.

exporters:
  # Экспорт трейсов в Jaeger
  otlp/jaeger:
    endpoint: jaeger:4317 # Эндпоинт Jaeger, принимающий OTLP формат
    # Коллектор отправляет данные в Jaeger по gRPC
    # Jaeger слушает на порту 4317 для приема данных от коллектора
    tls:
      insecure: true # Отключение TLS для локальной разработки
  
  # Экспорт данных в логи - полезно для отладки
  debug:
    # Уровень детализации логов
    verbosity: detailed

  # PROMETHEUS REMOTE WRITE - отправка метрик в Prometheus
  # Remote Write - это способ отправки метрик в Prometheus "проталкиванием" (push)
  # В отличие от обычного scraping, где Prometheus сам забирает данные
  prometheusremotewrite:
    # URL endpoint Prometheus для приема метрик
    # Prometheus автоматически предоставляет этот endpoint
    endpoint: http://prometheus:9090/api/v1/write

  # ELASTICSEARCH EXPORTER - отправка логов в Elasticsearch
  elasticsearch:
    
    # ENDPOINTS: список адресов Elasticsearch кластера
    # В production обычно несколько узлов для отказоустойчивости
    endpoints: ["http://elasticsearch:9200"]
    
    # TLS НАСТРОЙКИ: конфигурация безопасного соединения
    tls:
      # INSECURE: отключаем проверку сертификатов для локальной разработки
      # В production ОБЯЗАТЕЛЬНО включить проверку сертификатов
      insecure: true
      
      # ДОПОЛНИТЕЛЬНЫЕ TLS НАСТРОЙКИ (для production):
      # cert_file: "/path/to/cert.pem"     # путь к сертификату клиента
      # key_file: "/path/to/key.pem"       # путь к приватному ключу
      # ca_file: "/path/to/ca.pem"         # путь к CA сертификату
    
    # LOGS INDEX: имя индекса для хранения логов в Elasticsearch
    # Все логи будут сохраняться в индекс "otel-logs-%{+yyyy.MM.dd}"
    # Можно использовать шаблоны: "logs-%{+yyyy.MM.dd}" для создания daily индексов
    # logs_index: "otel-logs-%{+yyyy.MM.dd}"
    logs_index: "otel-logs"
    
    # MAPPING: настройки индексации данных
    mapping:
      # ECS MODE: использовать Elastic Common Schema
      # Стандартизирует структуру полей логов для лучшей совместимости
      mode: ecs
      
      # ECS обеспечивает:
      # - @timestamp: временная метка лога
      # - message: текст сообщения  
      # - event.severity: уровень логирования
      # - service.name: имя сервиса
      # - и другие стандартизированные поля
    
    # ДОПОЛНИТЕЛЬНЫЕ НАСТРОЙКИ (можно добавить):
    # retry:
    #   enabled: true               # включить повторные попытки
    #   max_requests: 5             # максимум попыток
    #   initial_interval: 100ms     # начальная задержка
    # timeout: 90s                  # таймаут HTTP запроса
    # compression: gzip             # сжатие данных

# ===================================================================
# EXTENSIONS - ДОПОЛНИТЕЛЬНЫЕ КОМПОНЕНТЫ
# ===================================================================
# 
# Extensions предоставляют дополнительную функциональность коллектора.

extensions:
  
  # HEALTH CHECK: эндпоинт для проверки здоровья коллектора
  # Полезно для мониторинга в Kubernetes/Docker
  health_check:
    # ENDPOINT: адрес для health check запросов
    endpoint: 0.0.0.0:13133
    
    # Доступные эндпоинты:
    # - GET /health/status - общий статус
    # - GET /health/ready  - готовность к работе

# ===================================================================
# SERVICE - КОНФИГУРАЦИЯ СЕРВИСА КОЛЛЕКТОРА
# ===================================================================
# 
# Service определяет, как работает сам коллектор.

service:
  
  # TELEMETRY: собственная телеметрия коллектора
  telemetry:
    metrics:
      # READERS: новый формат конфигурации метрик (замена устаревшему address)
      # Здесь мы настраиваем Prometheus reader, который отдает метрики коллектора
      # по адресу http://localhost:8888/metrics
      readers:
        - pull:
            exporter:
              prometheus:
                host: 0.0.0.0
                port: 8888
      # Примеры метрик коллектора:
      # - otelcol_receiver_accepted_log_records_total: принятые логи
      # - otelcol_exporter_sent_log_records_total: отправленные логи  
      # - otelcol_processor_batch_batch_send_size: размеры батчей
  
  # EXTENSIONS: включаем дополнительные компоненты
  extensions: [health_check]
  
  # PIPELINES: определяем потоки обработки данных
  pipelines:
    # Пайплайн для трейсов
    traces:
      # Используемые приемники данных
      receivers: [otlp]
      # Последовательность обработчиков для трансформации данных
      # ВАЖНО: сначала семплируем (отбрасываем лишние), потом батчуем (группируем нужные)
      processors: [probabilistic_sampler, batch]
      # Куда отправлять обработанные трейсы
      exporters: [otlp/jaeger, debug]

    # Пайплайн для метрик
    # Обрабатывает только метрики (счетчики, гистограммы, gauge)
    metrics:
      # Источники данных - получаем метрики от UFO приложения через OTLP
      receivers: [otlp]
      # Последовательность обработки данных (порядок важен!)
      # batch - группировка для эффективности отправки
      processors: [batch]
      # Отправляем обработанные метрики в Prometheus
      exporters: [prometheusremotewrite]

    # LOGS PIPELINE: обработка логов
    logs:
      # ПОСЛЕДОВАТЕЛЬНОСТЬ ОБРАБОТКИ: receivers → processors → exporters
      
      receivers: [otlp]                    # принимаем от OTLP (gRPC на 4317 или HTTP на 4318)
      processors: [resource, batch]       # обогащаем метаданными, группируем в батчи  
      exporters: [elasticsearch]          # отправляем в Elasticsearch
      
      # FLOW ДИАГРАММА:
      # Go App (OTLP gRPC на порт 4317 или OTLP HTTP на порт 4318)
      #       ↓
      # OTLP Receiver (ports 4317 для gRPC, 4318 для HTTP)
      #       ↓  
      # Resource Processor (add service.name, deployment.environment)
      #       ↓
      # Batch Processor (group 1000 records, max 5s)  
      #       ↓
      # Elasticsearch Exporter (send to easy-logs index)

# ===================================================================
# ДОПОЛНИТЕЛЬНЫЕ ВОЗМОЖНОСТИ КОНФИГУРАЦИИ
# ===================================================================
#
# Примеры расширенной конфигурации для production:
#
# processors:
#   memory_limiter:                # ограничение памяти
#     limit_percentage: 80
#     spike_limit_percentage: 25
#   
#   attributes:                    # манипуляции с атрибутами
#     actions:
#       - key: environment
#         value: production
#         action: upsert
#       - key: sensitive_field
#         action: delete           # удалить чувствительные данные
#
# exporters:
#   jaeger:                        # дополнительный экспортер трасс  
#     endpoint: jaeger:14250
#     tls:
#       insecure: true
#
# service:
#   pipelines:
#     traces:                      # pipeline для трасс
#       receivers: [otlp]
#       processors: [memory_limiter, resource, batch]
#       exporters: [jaeger]